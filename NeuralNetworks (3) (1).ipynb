{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9chEEiNSzkL0"
   },
   "source": [
    "# NEURAL NETWORK AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHHHH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4FEZ51o5u3a"
   },
   "source": [
    "{'10 SR': 0, '100 SR': 1, '200 SR': 2, '5 SR': 3, '5 SR Poly': 4, '50 SR': 5, '500 SR': 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjHHHFEFzqDm"
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZAz8s2Zzxfj"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVYUkxwko4BI",
    "outputId": "ca68a753-6839-438f-e073-0782c3b39801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\abdu\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\abdu\\anaconda3\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\abdu\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\abdu\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O_UulIE-o6Vs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy4WritNzzx1"
   },
   "source": [
    "### Load, Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67QLQBJ_zi_C",
    "outputId": "24c97eef-185b-4e8e-de09-3843f5719dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\Abdu\\\\Desktop\\\\Images Dataset\"\n",
    "# Define transformations for the images.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),       # Resize images to 256x256\n",
    "    transforms.ToTensor(),               # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.ImageFolder(root=path, transform=transform)\n",
    "dataset.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmZg_i8z56fV"
   },
   "source": [
    "### Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCU66yjU55Jx",
    "outputId": "e0bc39eb-7ef6-49bb-d4cd-502ce85a35c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size: 266\n",
      "Train Size: 1064\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "torch.manual_seed(42)  # Set the PyTorch seed\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Test Size: {len(test_dataset)}\\nTrain Size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RN2-XxLwH1Bp"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Assuming the input size is 256x256, after three pooling layers the size is 256/8 = 32\n",
    "        # Adjust the number below if the input size is different\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = x.view(-1, 128 * 32 * 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "m1wgkET4K1C7",
    "outputId": "ee1d4f74-119a-482a-c6fd-f62a55789576"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=17.11%, loss=23.7]\n",
      "Epoch [2/30]: 100%|██████████| 34/34 [01:11<00:00,  2.10s/it, accuracy=34.40%, loss=1.87]\n",
      "Epoch [3/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=50.94%, loss=1.33]\n",
      "Epoch [4/30]: 100%|██████████| 34/34 [01:11<00:00,  2.09s/it, accuracy=50.75%, loss=1.27]\n",
      "Epoch [5/30]: 100%|██████████| 34/34 [01:13<00:00,  2.15s/it, accuracy=56.67%, loss=1.09]\n",
      "Epoch [6/30]: 100%|██████████| 34/34 [01:12<00:00,  2.14s/it, accuracy=64.76%, loss=0.92] \n",
      "Epoch [7/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=66.82%, loss=0.836]\n",
      "Epoch [8/30]: 100%|██████████| 34/34 [01:10<00:00,  2.08s/it, accuracy=68.23%, loss=0.796]\n",
      "Epoch [9/30]: 100%|██████████| 34/34 [01:10<00:00,  2.06s/it, accuracy=69.17%, loss=0.745]\n",
      "Epoch [10/30]: 100%|██████████| 34/34 [01:11<00:00,  2.10s/it, accuracy=77.35%, loss=0.569]\n",
      "Epoch [11/30]: 100%|██████████| 34/34 [01:11<00:00,  2.10s/it, accuracy=82.71%, loss=0.443]\n",
      "Epoch [12/30]: 100%|██████████| 34/34 [01:10<00:00,  2.09s/it, accuracy=87.59%, loss=0.363]\n",
      "Epoch [13/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=91.35%, loss=0.285]\n",
      "Epoch [14/30]: 100%|██████████| 34/34 [01:12<00:00,  2.13s/it, accuracy=90.23%, loss=0.27] \n",
      "Epoch [15/30]: 100%|██████████| 34/34 [01:11<00:00,  2.12s/it, accuracy=93.23%, loss=0.218]\n",
      "Epoch [16/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=94.64%, loss=0.187]\n",
      "Epoch [17/30]: 100%|██████████| 34/34 [01:13<00:00,  2.15s/it, accuracy=93.89%, loss=0.192]\n",
      "Epoch [18/30]: 100%|██████████| 34/34 [01:09<00:00,  2.05s/it, accuracy=89.85%, loss=0.276] \n",
      "Epoch [19/30]: 100%|██████████| 34/34 [01:09<00:00,  2.04s/it, accuracy=94.92%, loss=0.189]\n",
      "Epoch [20/30]: 100%|██████████| 34/34 [01:09<00:00,  2.05s/it, accuracy=91.35%, loss=0.27] \n",
      "Epoch [21/30]: 100%|██████████| 34/34 [01:10<00:00,  2.07s/it, accuracy=94.74%, loss=0.18] \n",
      "Epoch [22/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=89.10%, loss=0.28]  \n",
      "Epoch [23/30]: 100%|██████████| 34/34 [01:09<00:00,  2.05s/it, accuracy=88.82%, loss=0.358]\n",
      "Epoch [24/30]: 100%|██████████| 34/34 [01:11<00:00,  2.10s/it, accuracy=93.42%, loss=0.17] \n",
      "Epoch [25/30]: 100%|██████████| 34/34 [01:12<00:00,  2.12s/it, accuracy=97.27%, loss=0.0877]\n",
      "Epoch [26/30]: 100%|██████████| 34/34 [01:11<00:00,  2.10s/it, accuracy=97.27%, loss=0.0867]\n",
      "Epoch [27/30]: 100%|██████████| 34/34 [01:11<00:00,  2.11s/it, accuracy=96.52%, loss=0.096] \n",
      "Epoch [28/30]: 100%|██████████| 34/34 [01:10<00:00,  2.08s/it, accuracy=98.40%, loss=0.0537]\n",
      "Epoch [29/30]: 100%|██████████| 34/34 [01:11<00:00,  2.10s/it, accuracy=97.74%, loss=0.0719]\n",
      "Epoch [30/30]: 100%|██████████| 34/34 [01:09<00:00,  2.05s/it, accuracy=99.15%, loss=0.0373]\n"
     ]
    }
   ],
   "source": [
    "# Assuming model, train_loader, and criterion are already defined\n",
    "num_classes = len(dataset.classes)\n",
    "model = CNN(num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Make sure the model is in training mode which enables dropout etc.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(train_loader, leave=True)  # 'leave=True' ensures the final bar stays\n",
    "    for inputs, labels in loop:\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        outputs = model(inputs)  # Get model outputs\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagate the error\n",
    "        optimizer.step()  # Adjust model weights\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy and average loss\n",
    "        accuracy = 100 * correct / total\n",
    "        avg_loss = running_loss / (loop.n + 1)  # loop.n gives the current iteration number\n",
    "        \n",
    "        # Update the progress bar\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=avg_loss, accuracy=f\"{accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4G04NIrwK1jz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of the model is: 78.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87        48\n",
      "           1       0.74      0.86      0.79        29\n",
      "           2       0.82      0.86      0.84        43\n",
      "           3       0.62      0.65      0.63        37\n",
      "           4       0.58      0.53      0.55        34\n",
      "           5       0.97      0.90      0.93        39\n",
      "           6       0.80      0.78      0.79        36\n",
      "\n",
      "    accuracy                           0.78       266\n",
      "   macro avg       0.77      0.78      0.77       266\n",
      "weighted avg       0.78      0.78      0.78       266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize correct and total counters\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Lists to collect all predictions and true labels\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "# Evaluation mode and no gradient calculation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted_classes = torch.max(outputs, dim=1)[1]\n",
    "        \n",
    "        # Accumulate total and correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted_classes == labels).sum().item()\n",
    "\n",
    "        # Extend lists for classification report\n",
    "        all_predictions.extend(predicted_classes.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "print(f'The Accuracy of the model is: {(correct / total) * 100:.2f}%')\n",
    "\n",
    "# Generate and print classification report\n",
    "class_report = classification_report(all_labels, all_predictions)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Inputs\n",
    "\"\"\"\n",
    "input_image = \"PATH TO IMAGE\"\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "outputs = model(input_image)\n",
    "probabilities = F.softmax(outputs, dim=1)\n",
    "predicted_class = torch.argmax(probabilities, dim=1)\n",
    "max_probability = torch.max(probabilities, dim=1)\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class.item())\n",
    "print(\"Max Probability:\", max_probability.values.item())\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
